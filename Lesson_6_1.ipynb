{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson_6-1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/folamhmark/WORKSHOP-AI-2019-hometask-/blob/master/Lesson_6_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz4_lGlZ_A6G",
        "colab_type": "text"
      },
      "source": [
        "# –£—Ä–æ–∫ 6. –í–≤–µ–¥–µ–Ω–∏–µ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è: TensorFlow, Keras\n",
        "\n",
        "–ù–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —É—Ä–æ–∫–∞—Ö –º—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏–ª–∏—Å—å —Å –±–∞–∑–æ–≤—ã–º–∏ –ø–æ–Ω—è—Ç–∏—è–º–∏ —Ç–æ–≥–æ, —á—Ç–æ –∏–∑ —Å–µ–±—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏. –ú—ã —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–ª–∏ –æ–¥–Ω–æ—Å–ª–æ–π–Ω—ã–µ (shallow) –∏ –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ (deep) –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ (fully connected NN). –û–¥–Ω–∞–∫–æ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π —Å –Ω—É–ª—è –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥—è—Ç. –ù–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å –¥–æ—Å—Ç—É–ø–Ω–æ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –±–∏–±–ª–∏–æ—Ç–µ–∫ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á–∏ –ø–æ deep learning. –°—Ä–µ–¥–∏ –Ω–∏—Ö:\n",
        " - Tensorflow (Google);\n",
        " - Theano (University of Montreal);\n",
        " - PyTorch (Facebook);\n",
        " - Caffe (UC Berkeley);\n",
        " - MXNet (Apache);\n",
        " - CNTK (Microsoft).\n",
        " \n",
        "–í—Å–µ —ç—Ç–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏–º–µ—é—Ç –ø–æ–¥–¥–µ—Ä–∂–∫—É CUDA, —Ç–æ –µ—Å—Ç—å –º–æ–∂–Ω–æ –ø—Ä–æ–≤–æ–¥–∏—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–∞—Ö nvidia. –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å —ç—Ç–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ –º–æ–∂–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –¥—Ä—É–≥ –æ—Ç –¥—Ä—É–≥–∞ –ø–æ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å—É, –æ–¥–Ω–∞–∫–æ —Å—É—Ç—å –≤–µ–∑–¥–µ —Ç–∞ –∂–µ —Å–∞–º–∞—è: –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—é—Ç —à–∞–≥ forward –∏ backward propagation –∏ –æ—Å—É—â–µ—Å—Ç–≤–ª—è—é—Ç –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è —Å –∑–∞–¥–∞–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π –æ—à–∏–±–∫–∏ –∏ –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (–≤ —Ç.—á. –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–º).\n",
        "\n",
        "## Keras\n",
        "\n",
        "$\\textbf{Keras}$ —Ç–æ–∂–µ —á–∞—Å—Ç–æ –Ω–∞–∑—ã–≤–∞—é—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –æ–¥–Ω–∞–∫–æ —ç—Ç–æ –Ω–µ–≤–µ—Ä–Ω–æ. Keras - —ç—Ç–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å, —É–ø—Ä–æ—â–∞—é—â–∏–π –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –º–µ–∂–¥—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∏ –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (Keras –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç TensorFlow, Theano –∏ CNTK). –ï–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–æ–π –∏ –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–π, –≤—Å–ª–µ–¥—Å—Ç–≤–∏–µ —á–µ–≥–æ –æ–Ω —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ_BQj5nDapS",
        "colab_type": "text"
      },
      "source": [
        "## –ü—Ä–∏–º–µ—Ä –∑–∞–¥–∞—á –Ω–∞ TensorFlow\n",
        "\n",
        "–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –æ—à–∏–±–∫–∏ MSE\n",
        "\n",
        "$$loss = \\mathcal{L}(\\hat{y}, y) = (\\hat y^{(i)} - y^{(i)})^2: \\tag{1}$$\n",
        "\n",
        "```python\n",
        "y_hat = tf.constant(36, name='y_hat')            # Define y_hat constant. Set to 36.\n",
        "y = tf.constant(39, name='y')                    # Define y. Set to 39\n",
        "\n",
        "loss = tf.Variable((y - y_hat)**2, name='loss')  # Create a variable for the loss\n",
        "\n",
        "init = tf.global_variables_initializer()         # When init is run later (session.run(init)),\n",
        "                                                 # the loss variable will be initialized and ready to be computed\n",
        "with tf.Session() as session:                    # Create a session and print the output\n",
        "    session.run(init)                            # Initializes the variables\n",
        "    print(session.run(loss))                     # Prints the loss\n",
        "\n",
        "```\n",
        "\n",
        "–õ–æ–≥–∏–∫–∞ TensorFlow –≤ —Å–ª–µ–¥—É—é—â–µ–º: —Å–Ω–∞—á–∞–ª–∞ –º—ã –æ–ø–∏—Å—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–π, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –Ω–∏–∫–∞–∫–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞ –Ω–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç. –î–∞–ª–µ–µ –º—ã –¥–æ–ª–∂–Ω—ã –Ω–∞—á–∞—Ç—å —Ç.–Ω. \"—Å–µ—Å—Å–∏—é\" (session): –≤–æ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏ –±—É–¥—É—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –æ–ø–∏—Å–∞–Ω–Ω—ã–µ –Ω–∞–º–∏ —Ä–∞–Ω–µ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVPPYvItJ0At",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 1. –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ $y = (w-5)^2$ –ø–æ $w$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFahnvEgDMGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_2D-FFiD-wB",
        "colab_type": "code",
        "outputId": "b1bac505-3e97-4594-ad91-f55fc658fe2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w = tf.Variable(0,dtype = tf.float32)\n",
        "cost = tf.add(tf.add(w**2, tf.multiply(-10.,w)), 25)\n",
        "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "session = tf.Session()\n",
        "session.run(init)\n",
        "print(session.run(w))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Wjh_hADQP1",
        "colab_type": "code",
        "outputId": "4ba85a55-1d54-4ab8-f4d6-cdd7a9e445bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "session.run(train)\n",
        "print(session.run(w))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.099999994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyzSMi8JJRbe",
        "colab_type": "code",
        "outputId": "74ed628a-ecdf-457a-e67d-6ea3107f6e9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(100):\n",
        "  session.run(train)\n",
        "  print(session.run(w))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.198\n",
            "0.29404\n",
            "0.3881592\n",
            "0.480396\n",
            "0.5707881\n",
            "0.6593723\n",
            "0.7461849\n",
            "0.83126116\n",
            "0.91463596\n",
            "0.99634326\n",
            "1.0764164\n",
            "1.154888\n",
            "1.2317903\n",
            "1.3071545\n",
            "1.3810115\n",
            "1.4533913\n",
            "1.5243235\n",
            "1.593837\n",
            "1.6619602\n",
            "1.728721\n",
            "1.7941467\n",
            "1.8582637\n",
            "1.9210985\n",
            "1.9826765\n",
            "2.0430229\n",
            "2.1021624\n",
            "2.160119\n",
            "2.2169166\n",
            "2.2725782\n",
            "2.3271267\n",
            "2.3805842\n",
            "2.4329727\n",
            "2.4843132\n",
            "2.534627\n",
            "2.5839343\n",
            "2.6322556\n",
            "2.6796105\n",
            "2.7260182\n",
            "2.7714977\n",
            "2.8160677\n",
            "2.8597465\n",
            "2.9025514\n",
            "2.9445004\n",
            "2.9856105\n",
            "3.0258982\n",
            "3.0653803\n",
            "3.1040728\n",
            "3.1419914\n",
            "3.1791515\n",
            "3.2155685\n",
            "3.2512572\n",
            "3.286232\n",
            "3.3205073\n",
            "3.3540971\n",
            "3.387015\n",
            "3.4192748\n",
            "3.4508893\n",
            "3.4818716\n",
            "3.5122342\n",
            "3.5419896\n",
            "3.5711498\n",
            "3.599727\n",
            "3.6277323\n",
            "3.6551776\n",
            "3.682074\n",
            "3.7084327\n",
            "3.7342641\n",
            "3.759579\n",
            "3.7843874\n",
            "3.8086996\n",
            "3.8325257\n",
            "3.8558753\n",
            "3.8787577\n",
            "3.9011827\n",
            "3.923159\n",
            "3.9446957\n",
            "3.9658017\n",
            "3.9864857\n",
            "4.006756\n",
            "4.026621\n",
            "4.046088\n",
            "4.0651665\n",
            "4.0838633\n",
            "4.102186\n",
            "4.1201425\n",
            "4.1377397\n",
            "4.154985\n",
            "4.171885\n",
            "4.1884475\n",
            "4.2046785\n",
            "4.220585\n",
            "4.236173\n",
            "4.2514496\n",
            "4.2664204\n",
            "4.281092\n",
            "4.29547\n",
            "4.309561\n",
            "4.3233695\n",
            "4.336902\n",
            "4.350164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrGJjXo3KjxN",
        "colab_type": "text"
      },
      "source": [
        "**–ó–∞–º–µ—á–∞–Ω–∏–µ 1.** –ù–∞ –ø—Ä–∏–º–µ—Ä–µ –≤–∏–¥–Ω–æ, —á—Ç–æ —Ç–µ–ø–µ—Ä—å –Ω–∞–º –º–æ–∂–Ω–æ –Ω–µ –∑–∞–±–æ—Ç–∏—Ç—å—Å—è –æ –ø—Ä–æ—Ü–µ–¥—É—Ä–µ –≤–∑—è—Ç–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö - —ç—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏—è minimize –∫–ª–∞—Å—Å–∞ GradientDescentOptimizer. –ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –Ω–∞–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —à–∞–≥ forward propagation, –∞ backpropagation –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.\n",
        "\n",
        "**–ó–∞–º–µ—á–∞–Ω–∏–µ 2.** –î–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–≤–∏—Å–µ–ª–∞ —Ç–æ–ª—å–∫–æ –æ—Ç –æ–¥–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π, –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä–æ–π –±—ã–ª–æ –∑–∞—Ä–∞–Ω–µ–µ –∏–∑–≤–µ—Å—Ç–Ω–æ. –û–¥–Ω–∞–∫–æ —Ñ—É–Ω–∫—Ü–∏—è –æ—à–∏–±–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏—Ç –µ—â–µ –∏ –æ—Ç –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞—Ä–∞–Ω–µ–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã (–Ω–∞ —ç—Ç–∞–ø–µ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏). –ß—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã —Å —Ç–∞–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–≥—Ä—É–±–æ –≥–æ–≤–æ—Ä—è, —Å –≤—Ö–æ–¥–Ω—ã–º –º–∞—Å—Å–∏–≤–æ–º X), –≤ TensorFlow —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "```python\n",
        "tf.placeholder(dtype, shape),\n",
        "```\n",
        "–≥–¥–µ dtype - —ç—Ç–æ —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö (int, float16, float32), –∞ shape - —ç—Ç–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω–æ–≥–æ –º–∞—Å—Å–∏–≤–∞."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huWIxXXlN0nf",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 2. –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏  $ùë¶=x_0\\cdot w^2 - x_1 \\cdot w + x_2$  –ø–æ  ùë§\n",
        "\n",
        "–ü—É—Å—Ç—å —Ç–µ–ø–µ—Ä—å —Ñ—É–Ω–∫—Ü–∏—è –æ—à–∏–±–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –Ω–µ —Ç–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º $w$, –Ω–æ –∏ –¥–∞–Ω–Ω—ã–º—ã $x$. –†–∞—Å—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —ç—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö tf.placeholder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoq01epMNzw2",
        "colab_type": "code",
        "outputId": "29d1f2fb-57c1-41c7-df93-9c55f0c2f406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "coefficients = np.array([[1.,10.,25.]])\n",
        "\n",
        "w = tf.Variable(0,dtype = tf.float32)\n",
        "x = tf.placeholder(dtype = tf.float32, shape = [1,3])\n",
        "cost = x[0][0] * w**2 - x[0][1] * w + x[0][2]\n",
        "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
        "\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "session = tf.Session()\n",
        "session.run(init)\n",
        "print(session.run(w))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewH3PsHiJnFX",
        "colab_type": "code",
        "outputId": "f0a6e49c-1845-4340-d901-9fa5f6c3a996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for i in range(1000):\n",
        "  session.run(train, feed_dict = {x:coefficients})\n",
        "print(session.run(w))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.999988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ASaBVlSGIP",
        "colab_type": "text"
      },
      "source": [
        "–ù–∞–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º –Ω–∞ TensorFlow –º–æ–∂–Ω–æ –æ–ø–∏—Å–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —à–∞–≥–∞–º–∏:\n",
        "\n",
        "1. –û–±—ä—è–≤–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ Tensors (variables), –Ω–∞–¥ –∫–æ—Ç–æ—Ä—ã–º–∏ –Ω–∏–∫–∞–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —Å–æ–≤–µ—Ä—à–µ–Ω–æ –ø–æ–∫–∞ –Ω–µ –±—É–¥–µ—Ç. \n",
        "2. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –º–µ–∂–¥—É —ç—Ç–∏–º–∏ Tensors.\n",
        "3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—åTensors. \n",
        "4. –°–æ–∑–¥–∞—Ç—å —Å–µ—Å—Å–∏—é. \n",
        "5. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Å—Å–∏—é, –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∫–æ—Ç–æ—Ä–æ–π –±—É–¥—É—Ç –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –≤—ã—à–µ–æ–ø–∏—Å–∞–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞–¥ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ Tensors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XST9RIFiVyRg",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 3. –ß—Ç–æ –±—É–¥–µ—Ç, –µ—Å–ª–∏ –Ω–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å Session?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5SNcwtaP9vK",
        "colab_type": "code",
        "outputId": "102c7e5c-bca3-45fe-edd8-4f2c5b8c99c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = tf.constant(2)\n",
        "b = tf.constant(10)\n",
        "c = tf.multiply(a,b)\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Mul_6:0\", shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnvW73jdV8bk",
        "colab_type": "code",
        "outputId": "f641bb1e-a51d-4ed3-89a2-dadfacabc676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "print(sess.run(c))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lru9Ir1IwTtV",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 4.  One-hot Encoding. –ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ —Ñ—É–Ω–∫—Ü–∏—è softmax\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1J0WflUO8DxWyQuHxcOQYBE1GhfEyOdeE\" style=\"width:665px;height:320px;\">\n",
        "\n",
        "–ü—É—Å—Ç—å –ø–µ—Ä–µ–¥ –Ω–∞–º–∏ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –∑–∞–¥–∞—á–∞ –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞–º –Ω–∞–¥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Ü–≤–µ—Ç —Å–≤–µ—Ç–æ—Ñ–æ—Ä–∞ –ø–æ –∫–∞–∫–∏–º-—Ç–æ –≤—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º. –¢–æ–≥–¥–∞ –∫–ª–∞—Å—Å–æ–≤ –±—É–¥–µ—Ç —Ç—Ä–∏: [–∫—Ä–∞—Å–Ω—ã–π, –∂–µ–ª—Ç—ã–π, –∑–µ–ª–µ–Ω—ã–π]. –ú—ã —É–∂–µ –Ω–µ –º–æ–∂–µ–º –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º —á–∏—Å–ª–æ–º –Ω–∞ –≤—ã—Ö–æ–¥–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ, —á—Ç–æ–±—ã –Ω–µ–π—Ä–æ—Å–µ—Ç—å –≤—ã–¥–∞–≤–∞–ª–∞ –≤—ã—Ö–æ–¥ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 3 (3 –≤ –¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ). –¢–æ–≥–¥–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∫–∞–∂–¥—ã–π —Ü–≤–µ—Ç —Å–≤–µ—Ç–æ—Ñ–æ—Ä–∞ —Ç–æ–∂–µ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–º. –ü—Ä–æ—Å—Ç–µ–π—à–∏–π —Å–ø–æ—Å–æ–± —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å - one-hot encoding. –¢–æ–≥–¥–∞:\n",
        " - –∫—Ä–∞—Å–Ω—ã–π = $(1, 0, 0)^T$;\n",
        " - –∂–µ–ª—Ç—ã–π = $(0,1,0)^T$;\n",
        " - –∑–µ–ª–µ–Ω—ã–π = $(0,0,1)^T$.\n",
        " \n",
        "–ù–∞ –≤—ã—Ö–æ–¥–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –±—É–¥–µ—Ç —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã–π –≤–µ–∫—Ç–æ—Ä, i-—É—é –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É –∫–æ—Ç–æ—Ä–æ–≥–æ –º–æ–∂–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞ –∫ i-–æ–º—É –∫–ª–∞—Å—Å—É. \n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å:\n",
        "\n",
        "$$J(y, \\hat y) = -\\frac{1}{N} \\sum_{s\\in S} \\sum_{c \\in C} 1_{s\\in c} \\log {p(s \\in c)}.$$\n",
        "\n",
        "–°—É–º–º–∞ –≤—Å–µ—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –¥–æ–ª–∂–Ω–∞ —Ä–∞–≤–Ω—è—Ç—å—Å—è –µ–¥–∏–Ω–∏—Ü–µ:\n",
        "\n",
        "$$\\forall l \\in[1,N]  \\quad\\sum_{i=1}^m y_i^{(l)} = 1,$$\n",
        "\n",
        "–≥–¥–µ N -–∫–æ–ª-–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤, l -–∫–æ–ª-–≤–æ –∫–ª–∞—Å—Å–æ–≤. –ß—Ç–æ–±—ã —Ç–∞–∫–æ–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω—è–ª–æ—Å—å, –≤–≤–æ–¥–∏—Ç—Å—è –Ω–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è $\\textit{Softmax}:$\n",
        "\n",
        "$$Softmax(z)_i = \\frac{\\exp{(z_i)}}{\\sum_{j=1}^m \\exp{(z_j)}}, \\quad i \\in [1,m]. $$\n",
        "\n",
        "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã —Å—É–º–º–∞ –≤—Å–µ—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç —Ä–∞–≤–Ω—è–ª–∞—Å—å –µ–¥–∏–Ω–∏—Ü–µ, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è (—Ä–∞–≤–Ω–æ –∫–∞–∫ –∏ —Ç–æ, —á—Ç–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å - —ç—Ç–æ –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è –≤–µ–ª–∏—á–∏–Ω–∞).\n",
        "\n",
        "–í TensorFlow –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ y –≤ one-hot –≤–µ–∫—Ç–æ—Ä—ã:\n",
        "\n",
        "- tf.one_hot(labels, depth, axis)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSHj-iPo2dh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_matrix(labels, C):\n",
        "    \"\"\"\n",
        "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
        "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
        "                     will be 1. \n",
        "                     \n",
        "    Arguments:\n",
        "    labels -- vector containing the labels \n",
        "    C -- number of classes, the depth of the one hot dimension\n",
        "    \n",
        "    Returns: \n",
        "    one_hot -- one hot matrix\n",
        "    \"\"\"\n",
        "    \n",
        "    # Create a tf.constant equal to C (depth), name it 'C'.\n",
        "    C = tf.constant(C, name = 'C')\n",
        "    \n",
        "    # Use tf.one_hot, be careful with the axis\n",
        "    one_hot_matrix = tf.one_hot(labels, C, axis=0)\n",
        "    \n",
        "    # Create the session\n",
        "    sess = tf.Session()\n",
        "    \n",
        "    # Run the session\n",
        "    one_hot = sess.run(one_hot_matrix)\n",
        "    \n",
        "    # Close the session\n",
        "    sess.close()\n",
        "    \n",
        "    \n",
        "    return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS_f40y22eT8",
        "colab_type": "code",
        "outputId": "4b3db42a-a688-4db0-fbb3-b5811214b4d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "labels = np.array([1,2,3,0,2,1])\n",
        "one_hot = one_hot_matrix(labels, C = 4)\n",
        "print (\"one_hot = \" + str(one_hot))\n",
        "print(type(one_hot))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one_hot = [[0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT9WDx1i6uCn",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 5. tf.layers\n",
        "\n",
        "–í TensorFlow –º–æ–∂–Ω–æ –ª–∏–±–æ –ø—Ä–æ–ø–∏—Å—ã–≤–∞—Ç—å —Å–∞–º–æ–º—É —Ü–µ–ø–æ—á–∫—É –≤—ã—á–∏—Å–ª–µ–Ω–∏–π, –ø—Ä–æ–∏—Å—Ö–æ–¥—è—â–∏—Ö –Ω–∞ –∫–∞–∂–¥–æ–º —Å–ª–æ–µ, –ª–∏–±–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≥–æ—Ç–æ–≤–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ tf.layers. –ú—ã –ø–æ–∫–∞ –∑–Ω–∞–∫–æ–º—ã —Ç–æ–ª—å–∫–æ —Å –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–º–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏ (fully connected NN), –∏—Ö —Å–ª–æ–∏ –Ω–∞–∑—ã–≤–∞—é—Ç—Å—è Dense layers. –ü—Ä–∏–º–µ—Ä –≤–Ω–∏–∑—É –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–∞–∫–æ–π —Å–ª–æ–π (–±–µ–∑ —à–∞–≥–∞ –æ–±—É—á–µ–Ω–∏—è!):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4Wck8-n7CbU",
        "colab_type": "code",
        "outputId": "ece0f61f-3b33-4202-b66e-20c771b60de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "y = tf.layers.dense(x, units=1, kernel_initializer=tf.zeros_initializer())\n",
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0722 09:57:01.969895 140552640759680 deprecation.py:323] From <ipython-input-21-7d9f41f4ec6c>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm82Jk8Y7tRE",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 6. –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è\n",
        "\n",
        "–õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è - —ç—Ç–æ –∑–∞–¥–∞—á–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∑–∞–∫–ª—é—á–∞—é—â–∞—è—Å—è –≤ –ª–∏–Ω–µ–π–Ω–æ–π –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π y:\n",
        "\n",
        "$$ y = Wx + b, \\quad J = \\sum(\\hat y_i - y_i)^2$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnbkNFbY7uHp",
        "colab_type": "code",
        "outputId": "43e749d5-658f-4f3e-f507-a74660e61121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "x = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)\n",
        "y_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)\n",
        "\n",
        "linear_model = tf.layers.Dense(units=1)\n",
        "\n",
        "y_pred = linear_model(x)\n",
        "loss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
        "train = optimizer.minimize(loss)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "for i in range(1000):\n",
        "  _, loss_value = sess.run((train, loss))\n",
        "  #print(loss_value)\n",
        "\n",
        "print(sess.run(y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.04127139]\n",
            " [-1.0199988 ]\n",
            " [-1.9987264 ]\n",
            " [-2.9774537 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXPnEJ2SWr5v",
        "colab_type": "text"
      },
      "source": [
        "### –ó–∞–¥–∞–Ω–∏–µ 1. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ª–∏–Ω–µ–π–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏  $y = W \\cdot x + b$\n",
        "\n",
        "–ü–µ—Ä–≤—ã–º –∑–∞–¥–∞–Ω–∏–µ–º –±—É–¥–µ—Ç –ø–æ–¥—Å—á–µ—Ç —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è: $Y = WX + b$, –≥–¥–µ $W$–∏  $X$ - —ç—Ç–æ —Å–ª—É—á–∞–π–Ω—ã–µ –º–∞—Ç—Ä–∏—Ü—ã, –∞ b - —Å–ª—É—á–∞–π–Ω—ã–π –≤–µ–∫—Ç–æ—Ä. \n",
        "\n",
        "**–ó–∞–¥–∞–Ω–∏–µ**: –†–∞—Å—Å—á–∏—Ç–∞—Ç—å $W\\cdot x + b$, –≥–¥–µ $W, x $, –∏ $b$ –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è. W –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä (4, 3), x - (3,1), b - (4,1). –í –∫–∞—á-–≤–µ –ø—Ä–∏–º–µ—Ä–∞ –ø–æ–∫–∞–∑–∞–Ω–æ, –∫–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±—ä—è–≤–ª–µ–Ω–∏–µ X —Å —Ä–∞–∑–º–µ—Ä–æ–º (3,1):\n",
        "```python\n",
        "X = tf.constant(np.random.randn(3,1), name = \"X\")\n",
        "\n",
        "```\n",
        "–¢–∞–∫–∂–µ –æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏: \n",
        "- tf.matmul(..., ...) - –ø–µ—Ä–µ–º–Ω–æ–∂–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü;\n",
        "- tf.add(..., ...) - —Å–ª–æ–∂–µ–Ω–∏–µ –¥–≤—É—Ö –æ–±—ä–µ–∫—Ç–æ–≤;\n",
        "- np.random.randn(...) - –º–µ—Ç–æ–¥ numpy –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–∞—Å—Å–∏–≤–æ–≤ —Å–ª—É—á–∞–π–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏.\n",
        "\n",
        "**NB** –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∞—Ä–≥—É–º–µ–Ω—Ç name —Ñ—É–Ω–∫—Ü–∏–∏ tf.constant. –ù–µ –∑–∞–±—É–¥—å—Ç–µ –µ–≥–æ —Ç–æ–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —É–∫–∞–∑–∞—Ç—å."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv4pXof4XKGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_function():\n",
        "    \"\"\"\n",
        "    Implements a linear function: \n",
        "            Initializes W to be a random tensor of shape (4,3)\n",
        "            Initializes X to be a random tensor of shape (3,1)\n",
        "            Initializes b to be a random tensor of shape (4,1)\n",
        "    Returns: \n",
        "    result -- runs the session for Y = WX + b \n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(1)\n",
        "    \n",
        "    ### START CODE HERE ### (4 lines of code)\n",
        "    X = tf.constant(np.random.randn(3, 1), name=\"X\")\n",
        "    W = tf.constant(np.random.randn(4, 3), name=\"W\")\n",
        "    b = tf.constant(np.random.randn(4, 1), name=\"b\")\n",
        "    Y = tf.add(tf.matmul(W, X), b)\n",
        "    ### END CODE HERE ### \n",
        "    \n",
        "    # Create the session using tf.Session() and run it with sess.run(...) on the variable you want to calculate\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    sess = tf.Session()\n",
        "    result = sess.run(Y)\n",
        "    ### END CODE HERE ### \n",
        "    \n",
        "    # close the session \n",
        "    sess.close()\n",
        "\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux5tNrrOZt6w",
        "colab_type": "text"
      },
      "source": [
        "### –ó–∞–¥–∞–Ω–∏–µ 2. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ (—Å–∏–≥–º–æ–∏–¥—ã)\n",
        "\n",
        "–ò—Ç–∞–∫, –º—ã —Ä–µ–∞–ª–∏–∑–æ–≤–∞–ª–∏ —Å–≤–µ—Ä—Ö—É –ª–∏–Ω–µ–π–Ω—É—é —á–∞—Å—Ç—å —à–∞–≥–∞ forward_propagation. Tensorflow —É–∂–µ –∏–º–µ–µ—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–∞–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∫–∞–∫ —Å–∏–≥–º–æ–∏–¥–∞ –∏–ª–∏ ReLU. –í –¥–∞–Ω–Ω–æ–º –∑–∞–¥–∞–Ω–∏–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —à–∞–≥ –ø–æ–¥—Å—á–µ—Ç–∞ —Å–∏–≥–º–æ–∏–¥—ã. \n",
        "\n",
        "–î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –Ω–∞–¥–æ –±—É–¥–µ—Ç –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–∏–ø–æ–º tf.placeholder. –ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–µ—Å—Å–∏–∏ –Ω–∞–¥–æ –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å feed_dict —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º z (—Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Ñ—É–Ω–∫—Ü–∏–∏).\n",
        "–ü–æ—Ä—è–¥–æ–∫ –±—É–¥–µ—Ç —Å–ª–µ–¥—É—é—â–∏–º:\n",
        " - —Å–æ–∑–¥–∞—Ç—å placeholder x;\n",
        " - –∑–∞–ø–∏—Å–∞—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–¥ –Ω–∏–º –±—É–¥—É—Ç –ø—Ä–æ–≤–æ–¥–∏—Ç—å—Å—è (tf.sigmoid);\n",
        " - –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Å—Å–∏—é.\n",
        "\n",
        "–°–µ—Å—Å–∏—é –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –¥–≤—É–º—è —Å–ø–æ—Å–æ–±–∞–º–∏: \n",
        "\n",
        "**–°–ø–æ—Å–æ–± 1:**\n",
        "```python\n",
        "sess = tf.Session()\n",
        "# –í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —à–∞–≥–∏\n",
        "result = sess.run(..., feed_dict = {...})\n",
        "sess.close() # –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Å—Å–∏–∏\n",
        "```\n",
        "** –°–ø–æ—Å–æ–± 2:**\n",
        "```python\n",
        "with tf.Session() as sess: \n",
        "    # –í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —à–∞–≥–∏\n",
        "    result = sess.run(..., feed_dict = {...})\n",
        "    # –ù–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —è–≤–Ω–æ –∑–∞–∫—Ä—ã–≤–∞—Ç—å —Å–µ—Å—Å–∏—é :)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo89bUribRt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Computes the sigmoid of z\n",
        "    \n",
        "    Arguments:\n",
        "    z -- input value, scalar or vector\n",
        "    \n",
        "    Returns: \n",
        "    results -- the sigmoid of z\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Create a placeholder for x. Name it 'x'.\n",
        "    x = tf.placeholder(tf.float32, name=\"x\")\n",
        "\n",
        "    # compute sigmoid(x)\n",
        "    \n",
        "    sigmoid = tf.sigmoid(x)\n",
        "\n",
        "    # Create a session, and run it.\n",
        "    # You should use a feed_dict to pass z's value to x. \n",
        "    \n",
        "    # Run session and call the output \"result\"\n",
        "    with tf.Session() as sess:\n",
        "        # Run session and call the output \"result\"\n",
        "        result = sess.run(sigmoid, feed_dict={x: z})\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXS-R_dGcKn7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ summary** \n",
        "\n",
        "–ù–∞ –¥–∞–Ω–Ω–æ–º —ç—Ç–∞–ø–µ –º—ã —É–∑–Ω–∞–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã—Ö –≤–µ—â–µ–π...\n",
        "  \n",
        "1. –ú—ã —É–∑–Ω–∞–ª–∏, —á—Ç–æ —Ç–∞–∫–æ–µ tf.Variable –∏ —á—Ç–æ —Ç–∞–∫–æ–µ tf.placeholder.\n",
        "2. –ù–∞—É—á–∏–ª–∏—Å—å –æ–±—ä—è–≤–ª—è—Ç—å –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏.\n",
        "3. –ù–∞—É—á–∏–ª–∏—Å—å —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–µ—Å—Å–∏—é.\n",
        "4. –ù–∞—É—á–∏–ª–∏—Å—å –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å —Å–µ—Å—Å–∏—é —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º feed_dict - —Å–ª–æ–≤–∞—Ä—è –¥–ª—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lMAiAzndK9U",
        "colab_type": "text"
      },
      "source": [
        "### –ó–∞–¥–∞–Ω–∏–µ 3 -  –ü–æ–¥—Å—á–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –æ—à–∏–±–∫–∏\n",
        "\n",
        "–ú–Ω–æ–≥–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—à–∏–±–∫–∏ —Ç–∞–∫–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ TensorFlow, –≤ —Ç–æ–º —á–∏—Å–ª–µ –±–∏–Ω–∞—Ä–Ω–∞—è –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è: \n",
        "$$ J = - \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log a^{ [2] (i)} + (1-y^{(i)})\\log (1-a^{ [2] (i)} )\\large ).\\small\\tag{2}$$\n",
        "\n",
        "\n",
        "**–ó–∞–¥–∞–Ω–∏–µ**: –†–µ–∞–ª–∏–∑—É–π—Ç–µ –ø–æ–¥—Å—á–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –æ—à–∏–±–∫–∏, –∏—Å–ø–æ–ª—å–∑—É—è —Å–ª–µ–¥—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é: \n",
        "\n",
        "\n",
        "- `tf.nn.sigmoid_cross_entropy_with_logits(logits = ...,  labels = ...)`\n",
        "\n",
        "–®–∞–≥–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–µ–¥—É—é—â–∏–º–∏: –ø–æ–¥–∞—Ç—å —Å–∏–≥–º–æ–∏–¥–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ z, –ø–æ—Å—á–∏—Ç–∞—Ç—å —Å–∏–≥–º–æ–∏–¥—É, –∑–∞—Ç–µ–º –≤—ã–∑–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –æ—à–∏–±–∫–∏, –≥–¥–µ logits - —ç—Ç–æ –≤—ã–≤–æ–¥ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å–∏–≥–º–æ–∏–¥—ã, labels - –∏—Å—Ç–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –±—É–¥–µ—Ç –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å—Å—è –ø–æ–¥—Å—á–µ—Ç —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è:\n",
        "\n",
        "$$- \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log \\sigma(z^{[2](i)}) + (1-y^{(i)})\\log (1-\\sigma(z^{[2](i)})\\large )\\small\\tag{2}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwmsy19zb7PQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost(logits, labels):\n",
        "    \"\"\"\n",
        "¬†¬†¬†¬†Computes the cost using the sigmoid cross entropy\n",
        "¬†¬†¬†¬†\n",
        "¬†¬†¬†¬†Arguments:\n",
        "¬†¬†¬†¬†logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)\n",
        "¬†¬†¬†¬†labels -- vector of labels y (1 or 0) \n",
        "    \n",
        "    Note: What we've been calling \"z\" and \"y\" in this class are respectively called \"logits\" and \"labels\" \n",
        "    in the TensorFlow documentation. So logits will feed into z, and labels into y. \n",
        "¬†¬†¬†¬†\n",
        "¬†¬†¬†¬†Returns:\n",
        "¬†¬†¬†¬†cost -- runs the session of the cost (formula (2))\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### \n",
        "    \n",
        "    # Create the placeholders for \"logits\" (z) and \"labels\" (y)\n",
        "    z = tf.placeholder(tf.float32, name=\"z\")\n",
        "    y = tf.placeholder(tf.float32, name=\"y\")\n",
        "    \n",
        "    \n",
        "    # Use the loss function \n",
        "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=z, labels=y)\n",
        "    \n",
        "    # Create a session (approx. 1 line). See method 1 above.\n",
        "    sess = tf.Session()\n",
        "    \n",
        "    # Run the session (approx. 1 line).\n",
        "    cost = sess.run(cost, feed_dict={z: logits, y: labels})\n",
        "    \n",
        "    # Close the session (approx. 1 line). See method 1 above.\n",
        "    sess.close()\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n42pi1afqbzh",
        "colab_type": "text"
      },
      "source": [
        "##Keras\n",
        "\n",
        "–ö–∞–∫ —É–∂–µ –±—ã–ª–æ —Å–∫–∞–∑–∞–Ω–æ —Ä–∞–Ω–µ–µ, Keras - —ç—Ç–æ –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –æ–±–æ–ª–æ—á–∫–∞ –Ω–∞–¥ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–º –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é Keras –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —è–¥—Ä–æ TensorFlow). –î–∞–ª–µ–µ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –Ω–∞ Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EVC-cxFq1I0",
        "colab_type": "text"
      },
      "source": [
        "### –ü—Ä–∏–º–µ—Ä 1. –î–≤—É—Å–ª–æ–π–Ω–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å –¥–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:\n",
        " - –≤—Ö–æ–¥ –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (1,100);\n",
        " - –ø–µ—Ä–≤—ã–π —Å–ª–æ–π –∏–º–µ–µ—Ç 32 –Ω–µ–π—Ä–æ–Ω–∞, —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ ReLU;\n",
        " - –≤—Ç–æ—Ä–æ–π —Å–ª–æ–π –∏–º–µ–µ—Ç 10 –Ω–µ–π—Ä–æ–Ω–æ–≤, —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ Softmax;\n",
        " - –≤ –∫–∞—á–µ—Å—Ç–≤–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è RMSProp;\n",
        " - —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä—ã –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è;\n",
        " - —Ñ—É–Ω–∫—Ü–∏—è –æ—à–∏–±–∫–∏: –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–∞—è –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è:\n",
        " $$ \\large CE = - \\large \\sum_i^C y_i \\log(Softmax(z)_i) = - \\large \\log(\\frac{\\exp{(z_i)}}{\\sum_{j=1}^m \\exp{(z_j)}}),$$\n",
        " \n",
        " –≥–¥–µ C -  –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUccb3rr5_fE",
        "colab_type": "code",
        "outputId": "6dc9b71e-9848-4782-9da9-a094cb5f5bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import numpy as np\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=100))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Generate dummy data\n",
        "\n",
        "data = np.random.random((1000, 100))\n",
        "labels = np.random.randint(10, size=(1000, 1))\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "W0722 10:10:02.283468 140552640759680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0722 10:10:02.285250 140552640759680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0722 10:10:02.292091 140552640759680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0722 10:10:02.324480 140552640759680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0722 10:10:02.346895 140552640759680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0722 10:10:02.538162 140552640759680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 0s 374us/step - loss: 2.3363 - acc: 0.0920\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 106us/step - loss: 2.3013 - acc: 0.1190\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 108us/step - loss: 2.2907 - acc: 0.1320\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 118us/step - loss: 2.2774 - acc: 0.1360\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 123us/step - loss: 2.2695 - acc: 0.1490\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 115us/step - loss: 2.2614 - acc: 0.1330\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 107us/step - loss: 2.2491 - acc: 0.1470\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 127us/step - loss: 2.2424 - acc: 0.1600\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 128us/step - loss: 2.2321 - acc: 0.1720\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 128us/step - loss: 2.2250 - acc: 0.1820\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd4a00ee710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQCbCkN8s-et",
        "colab_type": "text"
      },
      "source": [
        "–®–∞–≥–∏, –ø—Ä–æ–¥–µ–ª–∞–Ω–Ω—ã–µ –≤ Keras –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏, –ø–æ—Ö–æ–∂–∏ –Ω–∞ —Ç–µ, —á—Ç–æ –º—ã –ø—Ä–æ–¥–µ–ª—ã–≤–∞–ª–∏ –≤ TensorFlow:\n",
        " \n",
        " - 1) –æ–ø–∏—Å–∞–Ω–∏–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ - –æ–±—ä–µ–∫—Ç –∫–ª–∞—Å—Å–∞ Sequential;\n",
        " - 2) –∑–∞–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—à–∏–±–∫–∏ - –º–µ—Ç–æ–¥ compile;\n",
        " - 3) –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ - –º–µ—Ç–æ–¥  fit.\n",
        "–¢–µ–º –Ω–µ –º–µ–Ω–µ–µ, –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Keras –±–æ–ª–µ–µ user-friendly, —á—Ç–æ –Ω–∞–≥–ª—è–¥–Ω–æ –≤–∏–¥–Ω–æ –Ω–∞ –¥–∞–Ω–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ.\n",
        "\n",
        "**–í–∞–∂–Ω–æ–µ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ** –£ –∫–ª–∞—Å—Å–∞ model –µ—Å—Ç—å –º–µ—Ç–æ–¥ summary, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤—ã–≤–µ—Å—Ç–∏ –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏: –≤ –∫–∞–∫–æ–º —Å–ª–æ–µ —Å–∫–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ—è –∏ —Ç–¥."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAYBe9YhuA35",
        "colab_type": "code",
        "outputId": "9c03b314-56ae-40fe-8cf3-bbf25d44fe4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 32)                3232      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 3,562\n",
            "Trainable params: 3,562\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVBdS_IpuSo7",
        "colab_type": "text"
      },
      "source": [
        "–í –ø–µ—Ä–≤–æ–º —Å–ª–æ–µ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è 32x100 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ $w_{ij}$ –∏  32 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ $b_j$ - –≤—Å–µ–≥–æ 3232 –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞.\n",
        "\n",
        "–í–æ –≤—Ç–æ—Ä–æ–º —Å–ª–æ–µ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è 10—Ö32 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ $w_{ij}$ –∏ 10 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ $b_j$ - –≤—Å–µ–≥–æ 330 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
        "\n",
        "–î–∞–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç.–Ω. non-trainable parameters (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –Ω—É–∂–Ω–æ –ø–æ–¥–±–∏—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è), –æ–Ω–∏ –±—ã –ø–æ—è–≤–∏–ª–∏—Å—å, –µ—Å–ª–∏ –±—ã –º—ã –¥–æ–±–∞–≤–∏–ª–∏ batch_normalization. \n",
        "\n",
        "–¢–æ–≥–¥–∞ –Ω–∞ –∫–∞–∂–¥–æ–º —Å–ª–æ–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏–ª—Å—è –±—ã –ø–æ–¥—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ –∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ - —Ç–∞–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–∫ —Ä–∞–∑ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ non-trainable parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFSQszs8v8DK",
        "colab_type": "text"
      },
      "source": [
        "###–ü—Ä–∏–º–µ—Ä 2. –ó–∞–¥–∞—á–∞ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ Keras\n",
        "\n",
        "–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω –ø—Ä–∏–º–µ—Ä –∑–∞–¥–∞—á–∏, –∫–æ—Ç–æ—Ä—É—é –º—ã —É–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞–ª–∏ —Å –ø–æ–º–æ—â—å—é —Å—Ä–µ–¥—Å—Ç–≤ numpy - —ç—Ç–æ –∑–∞–¥–∞—á–∞ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–æ—Ç–Ω–µ—Å–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –ª–∏–±–æ –∫ –æ–¥–Ω–æ–º—É, –ª–∏–±–æ –∫ –¥—Ä—É–≥–æ–º—É –∫–ª–∞—Å—Å—É)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV6DZNLawPcw",
        "colab_type": "code",
        "outputId": "70730c1d-beb3-4b9f-b5c4-199a6ddcfd5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Generate dummy data\n",
        "x_train = np.random.random((1000, 20))\n",
        "y_train = np.random.randint(2, size=(1000, 1))\n",
        "x_test = np.random.random((100, 20))\n",
        "y_test = np.random.randint(2, size=(100, 1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=20, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128)\n",
        "score = model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0722 10:16:49.505267 140552640759680 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 0s 349us/step - loss: 0.7243 - acc: 0.4740\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 0s 39us/step - loss: 0.7171 - acc: 0.4760\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 0s 39us/step - loss: 0.6988 - acc: 0.5180\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 0s 39us/step - loss: 0.7082 - acc: 0.4950\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 0s 39us/step - loss: 0.7000 - acc: 0.5250\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 0s 37us/step - loss: 0.7026 - acc: 0.4960\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 0s 45us/step - loss: 0.7015 - acc: 0.4950\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 0s 38us/step - loss: 0.6982 - acc: 0.5210\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 0s 40us/step - loss: 0.6980 - acc: 0.5060\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 0s 43us/step - loss: 0.6983 - acc: 0.5130\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 0s 45us/step - loss: 0.6976 - acc: 0.5220\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 0s 43us/step - loss: 0.6971 - acc: 0.5080\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 0s 41us/step - loss: 0.6942 - acc: 0.5190\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 0s 40us/step - loss: 0.6968 - acc: 0.4990\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 0s 35us/step - loss: 0.6936 - acc: 0.5210\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 0s 36us/step - loss: 0.6923 - acc: 0.5230\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 0s 36us/step - loss: 0.6886 - acc: 0.5420\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 0s 38us/step - loss: 0.6915 - acc: 0.5260\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 0s 39us/step - loss: 0.6885 - acc: 0.5340\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 0s 37us/step - loss: 0.6882 - acc: 0.5380\n",
            "100/100 [==============================] - 0s 735us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es1NBQZjwgQe",
        "colab_type": "text"
      },
      "source": [
        "**–í–ê–ñ–ù–û** —É –º–æ–¥–µ–ª–∏ –µ—Å—Ç—å —Ç—Ä–∏ –º–µ—Ç–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ —Å–ø—É—Ç–∞—Ç—å –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º:\n",
        " - model.fit(...) - –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –ø—É—Ç–µ–º –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–¥–∞–Ω–Ω–æ–π –æ—à–∏–±–∫–∏ –∑–∞–¥–∞–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º (–Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞—é—Ç—Å—è x_train –∏ y_train);\n",
        " - model.evaluate(...) - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–æ–±—É—á–µ–Ω–∏—è –Ω–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç) (–Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞—é—Ç—Å—è x_test –∏ y_test);\n",
        " - model.predict(...) - –ø–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYekHqBhxgc1",
        "colab_type": "text"
      },
      "source": [
        "### –ó–∞–¥–∞–Ω–∏–µ –Ω–∞ Keras\n",
        "\n",
        "–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –Ω–∞ Keras –ª—é–±—É—é –∏–∑ —Ä–∞–Ω–µ–µ –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö –Ω–∞–º–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π (–º–æ–∂–Ω–æ –¥–∞–∂–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é). –í –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–Ω–æ –≤–∑—è—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Å –∫–æ—Ä–æ–±–æ—á–∫–∞–º–∏ –∏–ª–∏ –Ω–∞–±–æ—Ä —Ç–æ—á–µ–∫ –∏–∑ \"–ª–µ–ø–µ—Å—Ç–∫–æ–≤\".\n",
        "\n",
        "–î–æ–±–∞–≤–∏—Ç—å –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä dropout.\n",
        "\n",
        "–í–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–º adam.\n",
        "\n",
        "**–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ!** –ï—Å–ª–∏ –≤—ã –¥–æ–±–∞–≤–ª—è–µ—Ç–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä, —Ç–æ –Ω–∞–¥–æ —Ä–µ—à–∏—Ç—å, –¥–æ –∏–ª–∏ –ø–æ—Å–ª–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –µ–≥–æ –ø—Ä–∏–º–µ–Ω—è—Ç—å. –ß—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä –¥–æ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ù–ï –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç activation –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å–ª–æ—è Dense. –ê–∫—Ç–∏–≤–∞—Ü–∏—é –≤ —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –Ω–∞–¥–æ –¥–æ–±–∞–≤–∏—Ç—å –∫–∞–∫ —Å–ª–æ–π —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ dropout-a: keras.layers.Activation(activation=—Ñ—É–Ω–∫—Ü–∏—è_–∞–∫—Ç–∏–≤–∞—Ü–∏–∏)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfzeEAGv-qLn",
        "colab_type": "text"
      },
      "source": [
        "## PyTorch\n",
        "\n",
        "PyTorch - –µ—â–µ –æ–¥–∏–Ω —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–∏–º–µ—Ä –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏ –Ω–µ–∫–æ—Ç–æ—Ä–æ–π –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –¥–≤—É—Å–ª–æ–π–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guGm02Rfpq5_",
        "colab_type": "code",
        "outputId": "e2b3f03e-1366-434c-d732-f4d255cbfc2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out)\n",
        "    \n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y by passing x to the model.\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    print(t, loss.item())\n",
        "\n",
        "    # Before the backward pass, use the optimizer object to zero all of the\n",
        "    # gradients for the variables it will update (which are the learnable\n",
        "    # weights of the model). This is because by default, gradients are\n",
        "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
        "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    # parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Calling the step function on an Optimizer makes an update to its\n",
        "    # parameters\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 617.1824340820312\n",
            "1 600.6806640625\n",
            "2 584.6707153320312\n",
            "3 569.0603637695312\n",
            "4 553.8275756835938\n",
            "5 539.0787963867188\n",
            "6 524.8614501953125\n",
            "7 511.08837890625\n",
            "8 497.6931457519531\n",
            "9 484.7503662109375\n",
            "10 472.2181091308594\n",
            "11 460.0879821777344\n",
            "12 448.3591613769531\n",
            "13 437.0228576660156\n",
            "14 425.98846435546875\n",
            "15 415.3009338378906\n",
            "16 404.9441223144531\n",
            "17 394.8824462890625\n",
            "18 385.04730224609375\n",
            "19 375.5010986328125\n",
            "20 366.2279052734375\n",
            "21 357.1788635253906\n",
            "22 348.3672180175781\n",
            "23 339.82574462890625\n",
            "24 331.5387878417969\n",
            "25 323.49560546875\n",
            "26 315.62127685546875\n",
            "27 307.9244689941406\n",
            "28 300.40338134765625\n",
            "29 293.0827331542969\n",
            "30 285.9368591308594\n",
            "31 279.0050964355469\n",
            "32 272.2467346191406\n",
            "33 265.6567687988281\n",
            "34 259.2179870605469\n",
            "35 252.9234619140625\n",
            "36 246.79412841796875\n",
            "37 240.79286193847656\n",
            "38 234.91864013671875\n",
            "39 229.15802001953125\n",
            "40 223.5157470703125\n",
            "41 217.9838104248047\n",
            "42 212.59193420410156\n",
            "43 207.30865478515625\n",
            "44 202.126220703125\n",
            "45 197.05899047851562\n",
            "46 192.1124725341797\n",
            "47 187.2628936767578\n",
            "48 182.5348358154297\n",
            "49 177.8988800048828\n",
            "50 173.3536834716797\n",
            "51 168.9279022216797\n",
            "52 164.60946655273438\n",
            "53 160.38265991210938\n",
            "54 156.23541259765625\n",
            "55 152.17369079589844\n",
            "56 148.1888427734375\n",
            "57 144.2911376953125\n",
            "58 140.48304748535156\n",
            "59 136.75588989257812\n",
            "60 133.11073303222656\n",
            "61 129.54751586914062\n",
            "62 126.06597137451172\n",
            "63 122.66084289550781\n",
            "64 119.31897735595703\n",
            "65 116.05980682373047\n",
            "66 112.88253784179688\n",
            "67 109.76962280273438\n",
            "68 106.73243713378906\n",
            "69 103.76809692382812\n",
            "70 100.87024688720703\n",
            "71 98.03782653808594\n",
            "72 95.27731323242188\n",
            "73 92.58924102783203\n",
            "74 89.9570083618164\n",
            "75 87.39523315429688\n",
            "76 84.89901733398438\n",
            "77 82.45976257324219\n",
            "78 80.07501983642578\n",
            "79 77.75184631347656\n",
            "80 75.47757720947266\n",
            "81 73.2570571899414\n",
            "82 71.08965301513672\n",
            "83 68.97233581542969\n",
            "84 66.9050064086914\n",
            "85 64.89380645751953\n",
            "86 62.92571258544922\n",
            "87 61.00273513793945\n",
            "88 59.12947463989258\n",
            "89 57.29750061035156\n",
            "90 55.513343811035156\n",
            "91 53.777523040771484\n",
            "92 52.08591842651367\n",
            "93 50.43769836425781\n",
            "94 48.83586883544922\n",
            "95 47.277801513671875\n",
            "96 45.75826644897461\n",
            "97 44.279815673828125\n",
            "98 42.84294891357422\n",
            "99 41.440372467041016\n",
            "100 40.07583999633789\n",
            "101 38.74959945678711\n",
            "102 37.458839416503906\n",
            "103 36.20447540283203\n",
            "104 34.984962463378906\n",
            "105 33.800498962402344\n",
            "106 32.64912033081055\n",
            "107 31.530323028564453\n",
            "108 30.44285011291504\n",
            "109 29.38697052001953\n",
            "110 28.360198974609375\n",
            "111 27.36356544494629\n",
            "112 26.395965576171875\n",
            "113 25.457347869873047\n",
            "114 24.54741859436035\n",
            "115 23.666475296020508\n",
            "116 22.81095314025879\n",
            "117 21.98223876953125\n",
            "118 21.177867889404297\n",
            "119 20.39969825744629\n",
            "120 19.64600944519043\n",
            "121 18.915782928466797\n",
            "122 18.207149505615234\n",
            "123 17.522058486938477\n",
            "124 16.857728958129883\n",
            "125 16.21588897705078\n",
            "126 15.595190048217773\n",
            "127 14.994439125061035\n",
            "128 14.412691116333008\n",
            "129 13.84909439086914\n",
            "130 13.3042631149292\n",
            "131 12.776894569396973\n",
            "132 12.266849517822266\n",
            "133 11.774116516113281\n",
            "134 11.296932220458984\n",
            "135 10.836233139038086\n",
            "136 10.39064884185791\n",
            "137 9.960281372070312\n",
            "138 9.545329093933105\n",
            "139 9.145244598388672\n",
            "140 8.759252548217773\n",
            "141 8.386736869812012\n",
            "142 8.02785873413086\n",
            "143 7.6818389892578125\n",
            "144 7.348475456237793\n",
            "145 7.027523040771484\n",
            "146 6.718159198760986\n",
            "147 6.420486927032471\n",
            "148 6.134110927581787\n",
            "149 5.858894348144531\n",
            "150 5.594261169433594\n",
            "151 5.339602947235107\n",
            "152 5.095417022705078\n",
            "153 4.860571384429932\n",
            "154 4.635348796844482\n",
            "155 4.4193315505981445\n",
            "156 4.212400913238525\n",
            "157 4.013840675354004\n",
            "158 3.823641061782837\n",
            "159 3.64109468460083\n",
            "160 3.462815761566162\n",
            "161 3.289527654647827\n",
            "162 3.1215028762817383\n",
            "163 2.9590260982513428\n",
            "164 2.8023369312286377\n",
            "165 2.6516945362091064\n",
            "166 2.5072734355926514\n",
            "167 2.369091510772705\n",
            "168 2.237137794494629\n",
            "169 2.111180305480957\n",
            "170 1.991203784942627\n",
            "171 1.8773400783538818\n",
            "172 1.76915442943573\n",
            "173 1.666611909866333\n",
            "174 1.5696569681167603\n",
            "175 1.477920651435852\n",
            "176 1.3912746906280518\n",
            "177 1.3095711469650269\n",
            "178 1.2325578927993774\n",
            "179 1.1599000692367554\n",
            "180 1.091513991355896\n",
            "181 1.0271536111831665\n",
            "182 0.966550886631012\n",
            "183 0.909591794013977\n",
            "184 0.8559303879737854\n",
            "185 0.8055096864700317\n",
            "186 0.7580103278160095\n",
            "187 0.7134249210357666\n",
            "188 0.6714551448822021\n",
            "189 0.6319776773452759\n",
            "190 0.5948300361633301\n",
            "191 0.5599048137664795\n",
            "192 0.5270366668701172\n",
            "193 0.49612852931022644\n",
            "194 0.4670088291168213\n",
            "195 0.43962621688842773\n",
            "196 0.4138413667678833\n",
            "197 0.38957202434539795\n",
            "198 0.3667173385620117\n",
            "199 0.34519079327583313\n",
            "200 0.3249402940273285\n",
            "201 0.3058566153049469\n",
            "202 0.2878815829753876\n",
            "203 0.2709648311138153\n",
            "204 0.25504282116889954\n",
            "205 0.2400667816400528\n",
            "206 0.22595901787281036\n",
            "207 0.21267983317375183\n",
            "208 0.2001717984676361\n",
            "209 0.18841198086738586\n",
            "210 0.17733371257781982\n",
            "211 0.16691340506076813\n",
            "212 0.157107412815094\n",
            "213 0.14788609743118286\n",
            "214 0.13921217620372772\n",
            "215 0.1310501992702484\n",
            "216 0.12337417900562286\n",
            "217 0.1161571815609932\n",
            "218 0.10937398672103882\n",
            "219 0.10299817472696304\n",
            "220 0.09701580554246902\n",
            "221 0.09137417376041412\n",
            "222 0.08608029782772064\n",
            "223 0.081102654337883\n",
            "224 0.07642702013254166\n",
            "225 0.07203742861747742\n",
            "226 0.06790382415056229\n",
            "227 0.06402163952589035\n",
            "228 0.06037196144461632\n",
            "229 0.05694086104631424\n",
            "230 0.05371437221765518\n",
            "231 0.050679776817560196\n",
            "232 0.047825444489717484\n",
            "233 0.045140817761421204\n",
            "234 0.04261299595236778\n",
            "235 0.04023433104157448\n",
            "236 0.037994883954524994\n",
            "237 0.035887058824300766\n",
            "238 0.033901337534189224\n",
            "239 0.03203140199184418\n",
            "240 0.030268866568803787\n",
            "241 0.02860700711607933\n",
            "242 0.027041422203183174\n",
            "243 0.025565199553966522\n",
            "244 0.024172501638531685\n",
            "245 0.022858712822198868\n",
            "246 0.021619396284222603\n",
            "247 0.0204489566385746\n",
            "248 0.01934470795094967\n",
            "249 0.018302014097571373\n",
            "250 0.017317600548267365\n",
            "251 0.01638755388557911\n",
            "252 0.015509050339460373\n",
            "253 0.01467902772128582\n",
            "254 0.013894621282815933\n",
            "255 0.013153476640582085\n",
            "256 0.012452969327569008\n",
            "257 0.011790025047957897\n",
            "258 0.011163552291691303\n",
            "259 0.010571205988526344\n",
            "260 0.01001061499118805\n",
            "261 0.009480462409555912\n",
            "262 0.008978815749287605\n",
            "263 0.008504020050168037\n",
            "264 0.008054745383560658\n",
            "265 0.0076294573955237865\n",
            "266 0.007227017544209957\n",
            "267 0.006846104748547077\n",
            "268 0.006484957877546549\n",
            "269 0.0061433142982423306\n",
            "270 0.005819766782224178\n",
            "271 0.005513499025255442\n",
            "272 0.0052230809815227985\n",
            "273 0.0049481699243187904\n",
            "274 0.004687712527811527\n",
            "275 0.004440802149474621\n",
            "276 0.004206981975585222\n",
            "277 0.0039852992631495\n",
            "278 0.003775411518290639\n",
            "279 0.003576345043256879\n",
            "280 0.003387743141502142\n",
            "281 0.0032089930027723312\n",
            "282 0.003039540257304907\n",
            "283 0.0028789767529815435\n",
            "284 0.0027267092373222113\n",
            "285 0.0025824159383773804\n",
            "286 0.0024456139653921127\n",
            "287 0.002315942430868745\n",
            "288 0.00219303322955966\n",
            "289 0.0020765389781445265\n",
            "290 0.0019660869147628546\n",
            "291 0.0018614004366099834\n",
            "292 0.001762180239893496\n",
            "293 0.0016683636931702495\n",
            "294 0.0015790086472406983\n",
            "295 0.001494516502134502\n",
            "296 0.0014144766610115767\n",
            "297 0.0013385836500674486\n",
            "298 0.001266677281819284\n",
            "299 0.0011985276360064745\n",
            "300 0.0011339426273480058\n",
            "301 0.001072732382453978\n",
            "302 0.0010147800203412771\n",
            "303 0.0009598344913683832\n",
            "304 0.0009077672148123384\n",
            "305 0.0008584632887504995\n",
            "306 0.0008117866818793118\n",
            "307 0.0007675582892261446\n",
            "308 0.000725660880561918\n",
            "309 0.0006859663408249617\n",
            "310 0.0006483898032456636\n",
            "311 0.000612816249486059\n",
            "312 0.0005791351431980729\n",
            "313 0.0005472355987876654\n",
            "314 0.0005170399672351778\n",
            "315 0.000488452787976712\n",
            "316 0.00046140135964378715\n",
            "317 0.0004357955476734787\n",
            "318 0.00041155918734148145\n",
            "319 0.00038863596273586154\n",
            "320 0.00036693669972009957\n",
            "321 0.0003464095061644912\n",
            "322 0.00032699696021154523\n",
            "323 0.0003086342476308346\n",
            "324 0.00029126222943887115\n",
            "325 0.0002748437982518226\n",
            "326 0.00025930505944415927\n",
            "327 0.00024461784050799906\n",
            "328 0.0002307402901351452\n",
            "329 0.00021761583047918975\n",
            "330 0.00020522075647022575\n",
            "331 0.00019349661306478083\n",
            "332 0.0001824179635150358\n",
            "333 0.0001719590072752908\n",
            "334 0.00016206986038014293\n",
            "335 0.000152734704897739\n",
            "336 0.00014391914010047913\n",
            "337 0.00013558912905864418\n",
            "338 0.000127719875308685\n",
            "339 0.00012030128709739074\n",
            "340 0.00011329493281664327\n",
            "341 0.0001066805052687414\n",
            "342 0.00010043520160252228\n",
            "343 9.454330574953929e-05\n",
            "344 8.898792293621227e-05\n",
            "345 8.374386379728094e-05\n",
            "346 7.879912300268188e-05\n",
            "347 7.413043203996494e-05\n",
            "348 6.97355717420578e-05\n",
            "349 6.559079338330775e-05\n",
            "350 6.167710671434179e-05\n",
            "351 5.799349310109392e-05\n",
            "352 5.452246841741726e-05\n",
            "353 5.1247588999103755e-05\n",
            "354 4.816522778128274e-05\n",
            "355 4.525869371718727e-05\n",
            "356 4.252446160535328e-05\n",
            "357 3.99463351641316e-05\n",
            "358 3.752065822482109e-05\n",
            "359 3.523531268001534e-05\n",
            "360 3.3085860195569694e-05\n",
            "361 3.106255462625995e-05\n",
            "362 2.9156935852370225e-05\n",
            "363 2.7361844331608154e-05\n",
            "364 2.5677840312710032e-05\n",
            "365 2.4090451915981248e-05\n",
            "366 2.259853863506578e-05\n",
            "367 2.1196179659455083e-05\n",
            "368 1.9876568330801092e-05\n",
            "369 1.8635493688634597e-05\n",
            "370 1.7467897123424336e-05\n",
            "371 1.6374915503547527e-05\n",
            "372 1.534508373879362e-05\n",
            "373 1.4377539628185332e-05\n",
            "374 1.3469124496623408e-05\n",
            "375 1.2615521882253233e-05\n",
            "376 1.1815270227089059e-05\n",
            "377 1.1062717931054067e-05\n",
            "378 1.0356078746553976e-05\n",
            "379 9.69310804066481e-06\n",
            "380 9.072350621863734e-06\n",
            "381 8.487116247124504e-06\n",
            "382 7.940210707602091e-06\n",
            "383 7.426882802974433e-06\n",
            "384 6.945575933059445e-06\n",
            "385 6.49450657874695e-06\n",
            "386 6.070054951123893e-06\n",
            "387 5.675573447661009e-06\n",
            "388 5.302726549416548e-06\n",
            "389 4.954723408445716e-06\n",
            "390 4.628102487913566e-06\n",
            "391 4.322869244788308e-06\n",
            "392 4.037231519760098e-06\n",
            "393 3.7690494991693413e-06\n",
            "394 3.517971435940126e-06\n",
            "395 3.28303690366738e-06\n",
            "396 3.0642097499367082e-06\n",
            "397 2.8584001938725123e-06\n",
            "398 2.666218961167033e-06\n",
            "399 2.486945959390141e-06\n",
            "400 2.318331098649651e-06\n",
            "401 2.1618197934003547e-06\n",
            "402 2.014607161981985e-06\n",
            "403 1.877753220469458e-06\n",
            "404 1.7497412727607298e-06\n",
            "405 1.6294558236040757e-06\n",
            "406 1.5177163277257932e-06\n",
            "407 1.4128090697340667e-06\n",
            "408 1.315958002123807e-06\n",
            "409 1.2244282743267831e-06\n",
            "410 1.1397303296689643e-06\n",
            "411 1.060406816577597e-06\n",
            "412 9.8684301974572e-07\n",
            "413 9.176084745377011e-07\n",
            "414 8.530091690772679e-07\n",
            "415 7.931174650366302e-07\n",
            "416 7.371718879767286e-07\n",
            "417 6.848204066045582e-07\n",
            "418 6.362644171531429e-07\n",
            "419 5.912192477808276e-07\n",
            "420 5.49344861155987e-07\n",
            "421 5.100054067952442e-07\n",
            "422 4.7337076125586464e-07\n",
            "423 4.3953207295999164e-07\n",
            "424 4.0788916066958336e-07\n",
            "425 3.782583348765911e-07\n",
            "426 3.5105162510262744e-07\n",
            "427 3.2533756666452973e-07\n",
            "428 3.01790379353406e-07\n",
            "429 2.79988540796694e-07\n",
            "430 2.5958300398087886e-07\n",
            "431 2.4015875510485785e-07\n",
            "432 2.2280286771092506e-07\n",
            "433 2.0647280507546384e-07\n",
            "434 1.9121408456612699e-07\n",
            "435 1.7711496980155061e-07\n",
            "436 1.6372281663734611e-07\n",
            "437 1.5158306609919237e-07\n",
            "438 1.4032661965757143e-07\n",
            "439 1.299197265325347e-07\n",
            "440 1.200159687186897e-07\n",
            "441 1.1103603014817054e-07\n",
            "442 1.0278593265411473e-07\n",
            "443 9.494931418885244e-08\n",
            "444 8.776452631309439e-08\n",
            "445 8.110781379855325e-08\n",
            "446 7.499725995785411e-08\n",
            "447 6.925290563231101e-08\n",
            "448 6.401823071655599e-08\n",
            "449 5.902521493794666e-08\n",
            "450 5.4536389626491655e-08\n",
            "451 5.028105931614846e-08\n",
            "452 4.6498037420406035e-08\n",
            "453 4.289064037266144e-08\n",
            "454 3.956958138928712e-08\n",
            "455 3.6540569681164925e-08\n",
            "456 3.370472256847279e-08\n",
            "457 3.105720125518019e-08\n",
            "458 2.869046156206423e-08\n",
            "459 2.6421982823876533e-08\n",
            "460 2.439692536881921e-08\n",
            "461 2.2417227185655975e-08\n",
            "462 2.0656839794241932e-08\n",
            "463 1.9034191112154986e-08\n",
            "464 1.7553393405478346e-08\n",
            "465 1.613721423154857e-08\n",
            "466 1.4896537336994697e-08\n",
            "467 1.3715049540508062e-08\n",
            "468 1.2647176639291047e-08\n",
            "469 1.1618784157008122e-08\n",
            "470 1.0711022291332029e-08\n",
            "471 9.86553239101795e-09\n",
            "472 9.103131581866819e-09\n",
            "473 8.359350545106281e-09\n",
            "474 7.708833571484774e-09\n",
            "475 7.122970213657709e-09\n",
            "476 6.5288370265648155e-09\n",
            "477 6.013924913617075e-09\n",
            "478 5.5882924954175905e-09\n",
            "479 5.1452708760280075e-09\n",
            "480 4.7443338146990754e-09\n",
            "481 4.377713302972097e-09\n",
            "482 4.0506584753075e-09\n",
            "483 3.719878627350681e-09\n",
            "484 3.4445875041200225e-09\n",
            "485 3.175444351910528e-09\n",
            "486 2.933524312354052e-09\n",
            "487 2.7025390814117145e-09\n",
            "488 2.4873165749284e-09\n",
            "489 2.2970612079120656e-09\n",
            "490 2.141190114102187e-09\n",
            "491 1.9934323081116645e-09\n",
            "492 1.8417635194722948e-09\n",
            "493 1.7130040719237627e-09\n",
            "494 1.5861291169372294e-09\n",
            "495 1.4550086691045294e-09\n",
            "496 1.3607358573253237e-09\n",
            "497 1.2453514885990558e-09\n",
            "498 1.1711466241237645e-09\n",
            "499 1.0835615738002957e-09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmye5H7OEymw",
        "colab_type": "text"
      },
      "source": [
        "## Summary\n",
        "\n",
        "–ù–∞ —ç—Ç–æ–º —É—Ä–æ–∫–µ –º—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏–ª–∏—Å—å —Å —Ç—Ä–µ–º—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º–∏ –¥–ª—è deep-learning:\n",
        " - TensorFlow - —É–∑–Ω–∞–ª–∏ –ø–æ—Ä—è–¥–æ–∫ –Ω–∞–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º, —É–∑–Ω–∞–ª–∏ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö Variable –∏ placeholder;\n",
        " - Keras (–∫–æ—Ç–æ—Ä—ã–π –Ω–µ —Å–æ–≤—Å–µ–º —Ñ—Ä–µ–π–º–≤–æ—Ä–∫, –∞ —Å–∫–æ—Ä–µ–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å) - –Ω–∞–ø–∏—Å–∞–ª–∏ –≤ –Ω–µ–º –ø—Ä–æ—Å—Ç—É—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å;\n",
        " - PyTorch - –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –Ω–∞–ø–∏—Å–∞–ª–∏ –ø—Ä–æ—Å—Ç—É—é –¥–≤—É—Å–ª–æ–π–Ω—É—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å –∏ –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∏, –∫–∞–∫ –µ–µ –æ–±—É—á–∞—Ç—å.\n",
        "\n",
        "–ü–æ–º–∏–º–æ —ç—Ç–æ–≥–æ, –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª–∏ –∑–∞–¥–∞—á—É –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –∞ –∏–º–µ–Ω–Ω–æ:\n",
        " - —É–∑–Ω–∞–ª–∏, —á—Ç–æ —Ç–∞–∫–æ–µ —Ñ—É–Ω–∫—Ü–∏—è Softmax;\n",
        " - —É–∑–Ω–∞–ª–∏, —á—Ç–æ —Ç–∞–∫–æ–µ one-hot encoding –∏ –∫–∞–∫ –µ–≥–æ —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å –Ω–∞ tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ixtWxreEFXZ",
        "colab_type": "code",
        "outputId": "af56ba63-3ebf-4825-a7f6-47b712086766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul 22 10:26:44 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    68W / 149W |    153MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj7dg8BDjI4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}